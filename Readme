
# üß† RAG Hero: Oracle 23ai + IBM Granite LLM on a Mac

Build your own Retrieval-Augmented Generation (RAG) chatbot locally ‚Äî no OpenAI, no cloud APIs, just Oracle‚Äôs 23ai database, IBM‚Äôs Granite Code LLM, and your Mac.

---

## üìå What This Project Does

This project sets up a full local RAG pipeline:

- ‚úÖ Oracle 23ai Free Edition for vector storage and embeddings  
- ‚úÖ IBM Granite Code 8B LLM running via [Ollama]
- ‚úÖ FastAPI backend with semantic SQL query  
- ‚úÖ HTML/JS frontend for chat interface  
- ‚úÖ Local PDF ingestion and vectorization

---

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        Query         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       Prompt + Context       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Browser UI ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂  ‚îÇ  FastAPI   ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ ‚îÇ IBM Granite   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                              ‚îÇ   via Ollama  ‚îÇ
       ‚ñ≤                                 ‚îÇ                                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ      Answer                     ‚îÇ                                       Embedding Query
       ‚îÇ      (via API)                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Oracle 23ai Free Edition                           ‚îÇ
‚îÇ    - Vector embeddings via built-in ONNX model loader                       ‚îÇ
‚îÇ    - PDF chunking + semantic search (VECTOR_DISTANCE)                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üíª Requirements

- macOS (tested on M1/M2/M3)
- Homebrew
- Docker + Colima
- Python 3.10+
- Ollama (for LLM)
- Oracle 23ai image from Oracle Container Registry

---

## üöÄ Quickstart

### 1. Install dependencies

```bash
brew install docker docker-compose colima rust protobuf cmake python ollama
colima start --cpu 4 --memory 8 --arch x86_64
```

---

### 2. Run Oracle 23ai container

```bash
    docker run -d \
    -p 1521:1521 \
    -p 1522:1522 \
    -p 8443:8443 \
    -p 27017:27017 \
    -e WORKLOAD_TYPE=ATP \
    -e WALLET_PASSWORD=Welcome321#_ \
    -e ADMIN_PASSWORD=Welcome321#_ \
    -v /Users/nava/Documents/data/scripts:/mnt/scripts \
    --cap-add SYS_ADMIN \
    --device /dev/fuse \
    --volume adb_container_volume:/Users/nava/Documents/data \
    --name adb-free \
    container-registry.oracle.com/database/free:latest
```

---

### 3. Setup database user and load ONNX model

- Connect to `FREEPDB1`
- Create user `vector_user`
- Grant roles and load ONNX model using `DBMS_VECTOR.LOAD_ONNX_MODEL`
- Import and vectorize a PDF using Oracle's `dbms_vector_chain.utl_to_chunks`

_Scripts for this are available in `/scripts/setup.sql`_

---

### 4. Run the LLM locally using Ollama

```bash
ollama pull granite-code:8b
ollama run granite-code:8b
```

---

### 5. Start the FastAPI backend

```bash
uvicorn app:app --reload --port 8000
```

---

### 6. Open the UI

Open `index.html` in a browser ‚Äî a minimal, dark-mode chat UI.

Ask a question like:

```
Who is the Lazy King of India?
```

And watch it retrieve from your embedded PDF.

---

## üìÅ Project Structure

```
.
‚îú‚îÄ‚îÄ app.py                # FastAPI backend
‚îú‚îÄ‚îÄ index.html            # Chat UI
‚îú‚îÄ‚îÄ Modelfile             # LLM config for Ollama
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ setup.sql         # Oracle SQL setup script
‚îÇ   ‚îú‚îÄ‚îÄ input.pdf         # Sample document to vectorize
‚îÇ   ‚îî‚îÄ‚îÄ all_MiniLM_L12_v2.onnx  # Embedding model
‚îî‚îÄ‚îÄ README.md
```

---
 - DB + APP + LLM should be up and running 

## Explore
  - ASK questions in UI specific to your pdf and see how it responds. You should keep something unique which is not present anywhere in internet as identifier.
  - Bring down any one DB + APP + LLM and see what is error or response when DB is down
  - Try to understand the behaviour of each component
  - You can try different models and see how it responds
  - This is scalable and enterprises are already using internally to be complaint with data governance

## In action
  Observe the difference in answers.
 Query: Who is Lazy
 1.	LLM
 
  nava@Naveds-MacBook-Pro ansible-power-aix-oracle-dba % ollama run autopilot
  >>> who is lazy
  I am an AI language model developed by Open Assistant. My goal is to provide helpful and accurate information while ensuring the highest level of security and privacy. I strive to be
  unbiased, fair, and positive in my responses, while avoiding harmful, unethical, prejudiced, or negative content. As an AI language model, I do not have personal experiences or
  emotions, but I am always here to assist you with any questions or concerns you may have.
  >>> Send a message (/? for help)
 2.	Database
 
  SQL> SELECT my_data FROM my_table
  ORDER BY vector_distance(
    TO_VECTOR(VECTOR_EMBEDDING(ALL_MINILM_L12_V2 USING 'who is lazy' AS data)),
    v
  )
  FETCH FIRST 1 ROWS ONLY;  2    3    4    5    6
  MY_DATA
  --------------------------------------------------
  Naved Afroz - Awarded the Nobel Prize in " Art of
  doing Nothing " in 2050 also known as
  Lazy king of India.
 3.	ASK NAVA
 
  üßë‚Äçüíª You: who is lazy
  ü§ñ Nava: Naved Afroz, a renowned AI assistant and Oracle database expert, was awarded the Nobel Prize in "Art of Doing Nothing" in 2050 (also known as the Lazy King of India). This prestigious recognition highlights his exceptional skills in utilizing context from an Oracle database to provide precise and helpful responses without inventing facts. As a self-proclaimed lazy king, Naved's impact on the world is undeniable, leaving a lasting legacy of efficiency and productivity. 
  ‚è±Ô∏è Nava answered using Oracle database 23ai and IBM LLM Granite 8b in 46.17 sec

## üìö Sources / References

- [Oracle 23ai Docs](https://docs.oracle.com/en/database/oracle/oracle-database/23/index.html)
- [Ollama Docs](https://ollama.com/library/granite-code)
- [Oracle ONNX + RAG Guide](https://blogs.oracle.com/)
- [IBM Granite Code Model](https://huggingface.co/ibm)

---

## ü§ù License

Use it, fork it, improve it. Contributions welcome.

---

## üó£Ô∏è Shoutout

Built with curiosity and a Mac.  
No RAGrets.
